"79201 0.1"  yes, pop20
"=================================="  
Boosting round 0: training loss = 1.2895, validation loss = 1.2966
Boosting round 49: training loss = 0.5939, validation loss = 1.2093
Boosting round 99: training loss = 0.3508, validation loss = 1.2574
Training set score: 0.9275
Test set score: 0.5696
              precision    recall  f1-score   support

           1       0.62      0.90      0.73      6656
           2       0.37      0.22      0.27      1653
           3       0.33      0.15      0.21      1430
           4       0.31      0.09      0.14      1079
           5       0.22      0.02      0.04       661
           6       0.24      0.03      0.06       299

    accuracy                           0.57     11778
   macro avg       0.35      0.24      0.24     11778
weighted avg       0.49      0.57      0.50     11778

BoatWebSocketServer "boosting_type=gbdt,learning_rate=0.1"
start: 2023/05/10_22:18:20.00
end  : 2023/05/10_22:18:25.57
"79201 0.1"  yes, pop20
"=================================="  
Boosting round 0: training loss = 1.2895, validation loss = 1.2966
Boosting round 49: training loss = 0.5939, validation loss = 1.2093
Boosting round 99: training loss = 0.3508, validation loss = 1.2574
         importance
pd123           110
pk3t1           124
pk3t2           134
pk3t3           153
pk3t4           158
pk3t5           236
pk3t6           239
pk3t7           298
pk3t8           351
pk3t9           470
pk3t10          612
pk3t11          674
pk3t12          828
pk3t13          958
pk3t14         1187
pk3t15         1338
pk3t16         1443
pk3t17         1700
pk3t18         1890
pk3t19         2087
pk3t20         2242
pbo3t1           64
pbo3t2           80
pbo3t3           56
pbo3t4           52
pbo3t5           44
pbo3t6           38
pbo3t7           38
pbo3t8           34
pbo3t9           39
pbo3t10          35
pbo3t11          24
pbo3t12          34
pbo3t13          22
pbo3t14          27
pbo3t15          30
pbo3t16          28
pbo3t17          24
pbo3t18          28
pbo3t19          22
pbo3t20          49
Training set score: 0.9275
Test set score: 0.5696
              precision    recall  f1-score   support

           1       0.62      0.90      0.73      6656
           2       0.37      0.22      0.27      1653
           3       0.33      0.15      0.21      1430
           4       0.31      0.09      0.14      1079
           5       0.22      0.02      0.04       661
           6       0.24      0.03      0.06       299

    accuracy                           0.57     11778
   macro avg       0.35      0.24      0.24     11778
weighted avg       0.49      0.57      0.50     11778

BoatWebSocketServer "boosting_type=gbdt,learning_rate=0.1"
start: 2023/05/10_22:20:21.60
end  : 2023/05/10_22:20:25.95
"79201 0.1" no, pop20 
"=================================="  
Boosting round 0: training loss = 1.3129, validation loss = 1.3019
Boosting round 49: training loss = 0.7868, validation loss = 1.1855
Boosting round 99: training loss = 0.5796, validation loss = 1.2092
         importance
pd123           140
pk3t1           163
pk3t2           161
pk3t3           183
pk3t4           198
pk3t5           220
pk3t6           281
pk3t7           351
pk3t8           383
pk3t9           494
pk3t10          626
pk3t11          681
pk3t12          804
pk3t13         1016
pk3t14         1177
pk3t15         1361
pk3t16         1468
pk3t17         1698
pk3t18         1828
pk3t19         2075
pk3t20         2137
pbo3t1           59
pbo3t2           51
pbo3t3           50
pbo3t4           37
pbo3t5           37
pbo3t6           29
pbo3t7           33
pbo3t8           19
pbo3t9           27
pbo3t10          22
pbo3t11          23
pbo3t12          18
pbo3t13          23
pbo3t14          13
pbo3t15          25
pbo3t16          12
pbo3t17          12
pbo3t18          10
pbo3t19          15
pbo3t20          40
Training set score: 0.8307
Test set score: 0.5722
              precision    recall  f1-score   support

           1       0.62      0.90      0.74     11593
           2       0.37      0.22      0.28      2916
           3       0.37      0.17      0.23      2502
           4       0.35      0.12      0.18      1914
           5       0.24      0.04      0.07      1134
           6       0.31      0.04      0.08       583

    accuracy                           0.57     20642
   macro avg       0.38      0.25      0.26     20642
weighted avg       0.50      0.57      0.50     20642

BoatWebSocketServer "boosting_type=gbdt,learning_rate=0.1"
start: 2023/05/10_22:33:03.98
end  : 2023/05/10_22:33:10.18
"79201 0.1" 
"=================================="  
BoatWebSocketServer "boosting_type=gbdt,learning_rate=0.1"
start: 2023/05/10_22:36:03.60
end  : 2023/05/10_22:36:05.79
"79201 0.1"  no, pop10
"=================================="  
Boosting round 0: training loss = 1.3153, validation loss = 1.3013
Boosting round 49: training loss = 0.9017, validation loss = 1.1840
Boosting round 99: training loss = 0.7632, validation loss = 1.1995
         importance
pd123           378
pk3t1           314
pk3t2           462
pk3t3           711
pk3t4           959
pk3t5          1288
pk3t6          1576
pk3t7          1921
pk3t8          2145
pk3t9          2463
pk3t10         2792
pbo3t1          378
pbo3t2          315
pbo3t3          308
pbo3t4          278
pbo3t5          285
pbo3t6          260
pbo3t7          270
pbo3t8          265
pbo3t9          325
pbo3t10         307
Training set score: 0.7436
Test set score: 0.5727
              precision    recall  f1-score   support

           1       0.62      0.90      0.74     11593
           2       0.37      0.22      0.27      2916
           3       0.35      0.15      0.22      2502
           4       0.35      0.12      0.18      1914
           5       0.27      0.05      0.08      1134
           6       0.31      0.07      0.11       583

    accuracy                           0.57     20642
   macro avg       0.38      0.25      0.27     20642
weighted avg       0.50      0.57      0.50     20642

BoatWebSocketServer "boosting_type=gbdt,learning_rate=0.1"
start: 2023/05/10_22:37:43.67
end  : 2023/05/10_22:37:48.07
"79201 0.1"  yes, pop10
"=================================="  
Boosting round 0: training loss = 1.2953, validation loss = 1.2949
Boosting round 49: training loss = 0.7555, validation loss = 1.2055
Boosting round 99: training loss = 0.5795, validation loss = 1.2369
         importance
pd123           357
pk3t1           285
pk3t2           435
pk3t3           695
pk3t4           951
pk3t5          1288
pk3t6          1492
pk3t7          1889
pk3t8          2069
pk3t9          2427
pk3t10         2784
pbo3t1          390
pbo3t2          343
pbo3t3          372
pbo3t4          329
pbo3t5          302
pbo3t6          306
pbo3t7          297
pbo3t8          317
pbo3t9          310
pbo3t10         362
Training set score: 0.8202
Test set score: 0.5700
              precision    recall  f1-score   support

           1       0.62      0.90      0.74      6656
           2       0.37      0.22      0.28      1653
           3       0.34      0.16      0.22      1430
           4       0.30      0.09      0.14      1079
           5       0.21      0.03      0.06       661
           6       0.22      0.04      0.06       299

    accuracy                           0.57     11778
   macro avg       0.34      0.24      0.25     11778
weighted avg       0.49      0.57      0.50     11778

BoatWebSocketServer "boosting_type=gbdt,learning_rate=0.1"
start: 2023/05/10_22:43:11.59
end  : 2023/05/10_22:43:15.25
"79201 0.1"  
"=================================="  
Boosting round 0: training loss = 1.3024, validation loss = 1.3125
Boosting round 49: training loss = 0.5543, validation loss = 1.3243
Boosting round 99: training loss = 0.3017, validation loss = 1.3994
        importance
pd123          645
pk3t1         1584
pk3t2         1654
pk3t3         1739
pk3t4         1646
pk3t5         1670
pk3t6         1715
pk3t7         1706
pk3t8         1755
pk3t9         1816
pk3t10        2070
Training set score: 0.9614
Test set score: 0.5480
              precision    recall  f1-score   support

           1       0.59      0.93      0.72      6656
           2       0.24      0.09      0.13      1653
           3       0.23      0.07      0.11      1430
           4       0.17      0.03      0.05      1079
           5       0.13      0.01      0.01       661
           6       0.17      0.01      0.01       299

    accuracy                           0.55     11778
   macro avg       0.25      0.19      0.17     11778
weighted avg       0.42      0.55      0.44     11778

BoatWebSocketServer "boosting_type=gbdt,learning_rate=0.1"
start: 2023/05/10_22:51:10.30
end  : 2023/05/10_22:51:13.86
Boosting round 0: training loss = 1.2953, validation loss = 1.2949
Boosting round 49: training loss = 0.7555, validation loss = 1.2055
Boosting round 99: training loss = 0.5795, validation loss = 1.2369
         importance
pd123           357
pk3t1           285
pk3t2           435
pk3t3           695
pk3t4           951
pk3t5          1288
pk3t6          1492
pk3t7          1889
pk3t8          2069
pk3t9          2427
pk3t10         2784
pbo3t1          390
pbo3t2          343
pbo3t3          372
pbo3t4          329
pbo3t5          302
pbo3t6          306
pbo3t7          297
pbo3t8          317
pbo3t9          310
pbo3t10         362
Training set score: 0.8202
Test set score: 0.5700
              precision    recall  f1-score   support

           1       0.62      0.90      0.74      6656
           2       0.37      0.22      0.28      1653
           3       0.34      0.16      0.22      1430
           4       0.30      0.09      0.14      1079
           5       0.21      0.03      0.06       661
           6       0.22      0.04      0.06       299

    accuracy                           0.57     11778
   macro avg       0.34      0.24      0.25     11778
weighted avg       0.49      0.57      0.50     11778

BoatWebSocketServer "boosting_type=gbdt,learning_rate=0.1"
start: 2023/05/10_22:51:13.87
end  : 2023/05/10_22:51:17.10
"79201 0.1"  no, popk10
"=================================="  
Boosting round 0: training loss = 1.3196, validation loss = 1.3042
Boosting round 49: training loss = 0.9172, validation loss = 1.1999
Boosting round 99: training loss = 0.7648, validation loss = 1.2220
        importance
pd123          545
pk3t1          383
pk3t2          551
pk3t3          883
pk3t4         1185
pk3t5         1629
pk3t6         1915
pk3t7         2255
pk3t8         2554
pk3t9         2866
pk3t10        3234
Training set score: 0.7497
Test set score: 0.5717
              precision    recall  f1-score   support

           1       0.62      0.91      0.74     11593
           2       0.37      0.21      0.27      2916
           3       0.36      0.15      0.21      2502
           4       0.33      0.11      0.17      1914
           5       0.25      0.04      0.07      1134
           6       0.35      0.06      0.11       583

    accuracy                           0.57     20642
   macro avg       0.38      0.25      0.26     20642
weighted avg       0.50      0.57      0.50     20642

BoatWebSocketServer "boosting_type=gbdt,learning_rate=0.1"
start: 2023/05/10_22:52:32.82
end  : 2023/05/10_22:52:36.45
"79201 0.1"  no, popk20
"=================================="  
Boosting round 0: training loss = 1.3165, validation loss = 1.3049
Boosting round 49: training loss = 0.7943, validation loss = 1.1954
Boosting round 99: training loss = 0.5821, validation loss = 1.2200
        importance
pd123          149
pk3t1          175
pk3t2          166
pk3t3          185
pk3t4          197
pk3t5          259
pk3t6          283
pk3t7          367
pk3t8          418
pk3t9          532
pk3t10         647
pk3t11         710
pk3t12         842
pk3t13        1028
pk3t14        1192
pk3t15        1421
pk3t16        1525
pk3t17        1714
pk3t18        1863
pk3t19        2139
pk3t20        2188
Training set score: 0.8267
Test set score: 0.5731
              precision    recall  f1-score   support

           1       0.62      0.90      0.73     11593
           2       0.37      0.22      0.28      2916
           3       0.38      0.17      0.23      2502
           4       0.34      0.11      0.17      1914
           5       0.29      0.05      0.08      1134
           6       0.35      0.05      0.09       583

    accuracy                           0.57     20642
   macro avg       0.39      0.25      0.26     20642
weighted avg       0.50      0.57      0.50     20642

BoatWebSocketServer "boosting_type=gbdt,learning_rate=0.1"
start: 2023/05/10_22:58:14.51
end  : 2023/05/10_22:58:19.05
"79201 0.1"  
"=================================="  
BoatWebSocketServer "boosting_type=gbdt,learning_rate=0.1"
start: 2023/05/10_23:13:56.70
end  : 2023/05/10_23:13:57.76
"79201 0.1"  
"=================================="  
BoatWebSocketServer "boosting_type=gbdt,learning_rate=0.1"
start: 2023/05/10_23:14:47.33
end  : 2023/05/10_23:14:48.37
"79201 0.1"  no, mbo20
"=================================="  
Boosting round 0: training loss = 1.3179, validation loss = 1.3001
Boosting round 49: training loss = 1.0593, validation loss = 1.1592
Boosting round 99: training loss = 0.9927, validation loss = 1.1640
         importance
pd123          1516
mbo3t1          906
mbo3t2          871
mbo3t3          825
mbo3t4          789
mbo3t5          811
mbo3t6          733
mbo3t7          755
mbo3t8          825
mbo3t9          823
mbo3t10         922
mbo3t11         877
mbo3t12         793
mbo3t13         806
mbo3t14         790
mbo3t15         880
mbo3t16         730
mbo3t17         758
mbo3t18         959
mbo3t19         735
mbo3t20         896
Training set score: 0.6213
Test set score: 0.5814
              precision    recall  f1-score   support

           1       0.62      0.91      0.74     11593
           2       0.40      0.23      0.29      2916
           3       0.39      0.17      0.24      2502
           4       0.38      0.12      0.19      1914
           5       0.28      0.05      0.08      1134
           6       0.35      0.09      0.14       583

    accuracy                           0.58     20642
   macro avg       0.40      0.26      0.28     20642
weighted avg       0.51      0.58      0.51     20642

BoatWebSocketServer "boosting_type=gbdt,learning_rate=0.1"
start: 2023/05/10_23:15:08.82
end  : 2023/05/10_23:15:12.65
"79201 0.1"  no mbork20
"=================================="  
Boosting round 0: training loss = 1.3194, validation loss = 1.3017
Boosting round 49: training loss = 1.0762, validation loss = 1.1700
Boosting round 99: training loss = 1.0123, validation loss = 1.1745
         importance
pd123          1926
mbo3t1          566
mbo3t2          512
mbo3t3          655
mbo3t4          611
mbo3t5          689
mbo3t6          631
mbo3t7          754
mbo3t8          717
mbo3t9          829
mbo3t10         890
mbo3t11         833
mbo3t12         809
mbo3t13         861
mbo3t14         891
mbo3t15         847
mbo3t16         840
mbo3t17         846
mbo3t18        1072
mbo3t19         969
mbo3t20        1252
Training set score: 0.6308
Test set score: 0.5796
              precision    recall  f1-score   support

           1       0.62      0.91      0.74     11593
           2       0.40      0.22      0.28      2916
           3       0.39      0.16      0.23      2502
           4       0.38      0.12      0.19      1914
           5       0.25      0.04      0.07      1134
           6       0.33      0.09      0.14       583

    accuracy                           0.58     20642
   macro avg       0.39      0.26      0.27     20642
weighted avg       0.51      0.58      0.51     20642

BoatWebSocketServer "boosting_type=gbdt,learning_rate=0.1"
start: 2023/05/10_23:18:43.12
end  : 2023/05/10_23:18:47.16
"79201 0.1"  
"=================================="  
Boosting round 0: training loss = 1.3156, validation loss = 1.3026
Boosting round 49: training loss = 0.9236, validation loss = 1.2265
Boosting round 99: training loss = 0.8399, validation loss = 1.2494
         importance
pd123          8386
mbo3t1          349
mbo3t2          311
mbo3t3          427
mbo3t4          302
mbo3t5          461
mbo3t6          372
mbo3t7          467
mbo3t8          366
mbo3t9          504
mbo3t10         605
mbo3t11         522
mbo3t12         475
mbo3t13         464
mbo3t14         557
mbo3t15         536
mbo3t16         502
mbo3t17         473
mbo3t18         574
mbo3t19         551
mbo3t20         796
Training set score: 0.6883
Test set score: 0.5631
              precision    recall  f1-score   support

           1       0.62      0.88      0.73     11593
           2       0.37      0.22      0.28      2916
           3       0.34      0.18      0.23      2502
           4       0.31      0.12      0.18      1914
           5       0.21      0.05      0.09      1134
           6       0.27      0.10      0.15       583

    accuracy                           0.56     20642
   macro avg       0.35      0.26      0.27     20642
weighted avg       0.49      0.56      0.50     20642

BoatWebSocketServer "boosting_type=gbdt,learning_rate=0.1"
start: 2023/05/10_23:24:40.58
end  : 2023/05/10_23:24:48.10
"79201 0.1"  no, mb40
Boosting round 0: training loss = 1.3169, validation loss = 1.2995
Boosting round 49: training loss = 1.0517, validation loss = 1.1579
Boosting round 99: training loss = 0.9793, validation loss = 1.1632
           importance
pd123            1454
mbo3t1            629
mbo3t2            580
mbo3t3            577
mbo3t4            471
mbo3t5            482
mbo3t6            446
mbo3t7            494
mbo3t8            467
mbo3t9            511
mbo3t10           574
mbo3t11           560
mbo3t12           504
mbo3t13           502
mbo3t14           471
mbo3t15           568
mbo3t16           431
mbo3t17           559
mbo3t18           696
mbo3t19           495
mbo3t20           618
mbork3t1          205
mbork3t2          185
mbork3t3          254
mbork3t4          246
mbork3t5          250
mbork3t6          236
mbork3t7          251
mbork3t8          245
mbork3t9          301
mbork3t10         343
mbork3t11         279
mbork3t12         281
mbork3t13         287
mbork3t14         306
mbork3t15         352
mbork3t16         321
mbork3t17         353
mbork3t18         411
mbork3t19         359
mbork3t20         446
Training set score: 0.6320
Test set score: 0.5796
              precision    recall  f1-score   support

           1       0.62      0.91      0.74     11593
           2       0.39      0.22      0.28      2916
           3       0.38      0.16      0.23      2502
           4       0.37      0.12      0.18      1914
           5       0.25      0.04      0.07      1134
           6       0.31      0.07      0.12       583

    accuracy                           0.58     20642
   macro avg       0.39      0.26      0.27     20642
weighted avg       0.51      0.58      0.51     20642

BoatWebSocketServer "boosting_type=gbdt,learning_rate=0.1"
start: 2023/05/10_23:24:48.11
end  : 2023/05/10_23:24:53.52

****************************************************************************************
data_use_range=no, featureset=mbo_20で決定
****************************************************************************************

"79201 0.01"  
"=================================="  
Terminate batch job (Y/N)? 
"79201 0.01"  
"=================================="  
Boosting round 0: training loss = 1.3582, validation loss = 1.3335
Boosting round 49: training loss = 1.2264, validation loss = 1.2249
Boosting round 99: training loss = 1.1707, validation loss = 1.1842
         importance
pd123          1817
mbo3t1         1795
mbo3t2          927
mbo3t3         1082
mbo3t4          832
mbo3t5          895
mbo3t6          779
mbo3t7          869
mbo3t8          487
mbo3t9          706
mbo3t10        1329
mbo3t11         691
mbo3t12         614
mbo3t13         444
mbo3t14         809
mbo3t15         620
mbo3t16         545
mbo3t17         355
mbo3t18         861
mbo3t19         536
mbo3t20        1007
Training set score: 0.5720
Test set score: 0.5755
              precision    recall  f1-score   support

           1       0.58      0.98      0.73     11593
           2       0.49      0.10      0.17      2916
           3       0.47      0.05      0.09      2502
           4       0.49      0.02      0.04      1914
           5       1.00      0.01      0.01      1134
           6       0.61      0.02      0.04       583

    accuracy                           0.58     20642
   macro avg       0.61      0.20      0.18     20642
weighted avg       0.57      0.58      0.45     20642

BoatWebSocketServer "boosting_type=gbdt,learning_rate=0.01"
start: 2023/05/10_23:31:42.71
end  : 2023/05/10_23:31:46.90
"79201 0.09"  
"=================================="  
Boosting round 0: training loss = 1.3222, validation loss = 1.3036
Boosting round 49: training loss = 1.0675, validation loss = 1.1589
Boosting round 99: training loss = 1.0057, validation loss = 1.1627
         importance
pd123          1628
mbo3t1          954
mbo3t2          841
mbo3t3          813
mbo3t4          806
mbo3t5          724
mbo3t6          765
mbo3t7          807
mbo3t8          727
mbo3t9          789
mbo3t10         902
mbo3t11         882
mbo3t12         756
mbo3t13         858
mbo3t14         770
mbo3t15         860
mbo3t16         694
mbo3t17         768
mbo3t18        1002
mbo3t19         736
mbo3t20         918
Training set score: 0.6176
Test set score: 0.5819
              precision    recall  f1-score   support

           1       0.62      0.91      0.74     11593
           2       0.40      0.23      0.29      2916
           3       0.39      0.17      0.23      2502
           4       0.37      0.12      0.19      1914
           5       0.29      0.04      0.08      1134
           6       0.34      0.09      0.14       583

    accuracy                           0.58     20642
   macro avg       0.40      0.26      0.28     20642
weighted avg       0.51      0.58      0.51     20642

BoatWebSocketServer "boosting_type=gbdt,learning_rate=0.09"
start: 2023/05/10_23:32:24.14
end  : 2023/05/10_23:32:28.13
"79201 0.08"  
"=================================="  
Boosting round 0: training loss = 1.3265, validation loss = 1.3072
Boosting round 49: training loss = 1.0759, validation loss = 1.1571
Boosting round 99: training loss = 1.0179, validation loss = 1.1602
         importance
pd123          1716
mbo3t1          971
mbo3t2          877
mbo3t3          829
mbo3t4          744
mbo3t5          776
mbo3t6          751
mbo3t7          778
mbo3t8          767
mbo3t9          788
mbo3t10         895
mbo3t11         830
mbo3t12         726
mbo3t13         804
mbo3t14         769
mbo3t15         863
mbo3t16         701
mbo3t17         763
mbo3t18         975
mbo3t19         755
mbo3t20         922
Training set score: 0.6145
Test set score: 0.5817
              precision    recall  f1-score   support

           1       0.62      0.92      0.74     11593
           2       0.40      0.22      0.28      2916
           3       0.39      0.17      0.23      2502
           4       0.38      0.12      0.18      1914
           5       0.28      0.05      0.08      1134
           6       0.36      0.09      0.15       583

    accuracy                           0.58     20642
   macro avg       0.40      0.26      0.28     20642
weighted avg       0.51      0.58      0.51     20642

BoatWebSocketServer "boosting_type=gbdt,learning_rate=0.08"
start: 2023/05/10_23:33:08.07
end  : 2023/05/10_23:33:12.20
"79201 0.2"  
"=================================="  
Boosting round 0: training loss = 1.2796, validation loss = 1.2692
Boosting round 49: training loss = 0.9945, validation loss = 1.1755
Boosting round 99: training loss = 0.8830, validation loss = 1.1896
         importance
pd123          1169
mbo3t1          906
mbo3t2          822
mbo3t3          777
mbo3t4          775
mbo3t5          797
mbo3t6          785
mbo3t7          811
mbo3t8          813
mbo3t9          886
mbo3t10         928
mbo3t11         835
mbo3t12         825
mbo3t13         901
mbo3t14         748
mbo3t15         894
mbo3t16         737
mbo3t17         850
mbo3t18         989
mbo3t19         798
mbo3t20         954
Training set score: 0.6612
Test set score: 0.5763
              precision    recall  f1-score   support

           1       0.63      0.90      0.74     11593
           2       0.39      0.22      0.28      2916
           3       0.38      0.17      0.23      2502
           4       0.37      0.13      0.19      1914
           5       0.22      0.05      0.08      1134
           6       0.26      0.09      0.13       583

    accuracy                           0.58     20642
   macro avg       0.37      0.26      0.28     20642
weighted avg       0.51      0.58      0.51     20642

BoatWebSocketServer "boosting_type=gbdt,learning_rate=0.2"
start: 2023/05/10_23:33:53.06
end  : 2023/05/10_23:33:56.96
"79201 0.5"  
"=================================="  
Boosting round 0: training loss = 1.2146, validation loss = 1.2240
Boosting round 49: training loss = 0.9038, validation loss = 1.3742
Boosting round 99: training loss = 0.7592, validation loss = 1.5662
         importance
pd123           861
mbo3t1          942
mbo3t2          864
mbo3t3          906
mbo3t4          816
mbo3t5          808
mbo3t6          810
mbo3t7          836
mbo3t8          812
mbo3t9          896
mbo3t10         947
mbo3t11         932
mbo3t12         802
mbo3t13         909
mbo3t14         699
mbo3t15         969
mbo3t16         702
mbo3t17         825
mbo3t18        1004
mbo3t19         757
mbo3t20         903
Training set score: 0.7407
Test set score: 0.5250
              precision    recall  f1-score   support

           1       0.63      0.81      0.71     11593
           2       0.32      0.21      0.25      2916
           3       0.28      0.17      0.21      2502
           4       0.25      0.15      0.19      1914
           5       0.12      0.07      0.09      1134
           6       0.12      0.10      0.11       583

    accuracy                           0.53     20642
   macro avg       0.29      0.25      0.26     20642
weighted avg       0.47      0.53      0.48     20642

BoatWebSocketServer "boosting_type=gbdt,learning_rate=0.5"
start: 2023/05/10_23:34:41.22
end  : 2023/05/10_23:34:44.93
"79201 0.2"  
"=================================="  
Terminate batch job (Y/N)? 
BoatWebSocketServer "boosting_type=gbdt,learning_rate=0.2"
start: 2023/05/10_23:35:16.67
end  : 2023/05/10_23:35:18.28
"79201 0.3"  
"=================================="  
Boosting round 0: training loss = 1.2495, validation loss = 1.2461
Boosting round 49: training loss = 0.9449, validation loss = 1.2139
Boosting round 99: training loss = 0.7981, validation loss = 1.2483
         importance
pd123          1067
mbo3t1          914
mbo3t2          795
mbo3t3          872
mbo3t4          798
mbo3t5          793
mbo3t6          758
mbo3t7          822
mbo3t8          855
mbo3t9          902
mbo3t10         934
mbo3t11         866
mbo3t12         760
mbo3t13         882
mbo3t14         737
mbo3t15         905
mbo3t16         741
mbo3t17         860
mbo3t18        1034
mbo3t19         764
mbo3t20         941
Training set score: 0.7039
Test set score: 0.5625
              precision    recall  f1-score   support

           1       0.63      0.88      0.73     11593
           2       0.36      0.21      0.27      2916
           3       0.34      0.17      0.22      2502
           4       0.32      0.12      0.18      1914
           5       0.17      0.05      0.08      1134
           6       0.16      0.09      0.11       583

    accuracy                           0.56     20642
   macro avg       0.33      0.25      0.27     20642
weighted avg       0.49      0.56      0.50     20642

BoatWebSocketServer "boosting_type=gbdt,learning_rate=0.3"
start: 2023/05/10_23:35:19.64
end  : 2023/05/10_23:35:23.37
